{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "196d3141-3c24-4317-8e48-7c24184d00f3",
   "metadata": {},
   "source": [
    "# Part III: Data Driven Approaches\n",
    "\n",
    "In this tutorial, we want to explore some data driven methods for image reconstruction. We will consider the limited angle CT problem with additional noise on the sinogram. Our test images will be composed of simple shapes which can be loaded from the utils module. Namely, the shapes are created via random weighted norm balls in $\\ell^p$ norms, i.e., we consider sets\n",
    "\n",
    "$$ \\left\\{x\\in\\mathbb{R}^2: \\left(\\sum_{i=1}^2 w_i |x_i - m_i|^p\\right)^{1/p} < r\\right\\} $$\n",
    "\n",
    "where $r>0, w\\in\\mathbb{R}^2, m\\in\\mathbb{R}^2$ are sampled randomly.\n",
    "\n",
    "Let's look at the shapes this produces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df322f8a-6bc0-4949-9b8b-58425467ee74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from utils import random_weighted_norm\n",
    "\n",
    "IMG_SIZE = 64 # image size is set globally\n",
    "IMG_KWARGS = {'vmin':0., 'vmax':1., 'cmap':'bone'} # kwargs for plotting\n",
    "rwn = random_weighted_norm(img_size=IMG_SIZE)\n",
    "\n",
    "# plot all shapes\n",
    "P = 5\n",
    "fig, ax = plt.subplots(1, P, figsize=(20,15))\n",
    "\n",
    "for i in range(P):\n",
    "    ax[i].imshow(rwn(p=2**i)[0], **IMG_KWARGS)\n",
    "    ax[i].set_title('p=' + str(2**i))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a1d05eb-4459-452f-94b8-2f165dde6058",
   "metadata": {},
   "source": [
    "## Supervised learning with a post-processing approach\n",
    "\n",
    "We are interested in the limited angle CT problem. Namely, let $R$ denote the limited-angle Radon operator, then we intend to solve the inverse problem\n",
    "$$ y = Rx + \\epsilon.$$\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Question:</b> How do we incorporate data into our reconstruction method?\n",
    "</div>\n",
    "\n",
    "We first focus on so-called supervised learning, we are given a data set \n",
    "\n",
    "$$\\mathcal{T} = \\{(\\text{inp}_1,\\text{oup}_1), \\ldots, (\\text{inp}_T, \\text{oup}_T)\\}$$\n",
    "\n",
    "of $T$ input-output pairs. Furthermore, we use a **post-processing** approach. This means, we have a mapping $f:X\\to X$ and the reconstruction is defined is\n",
    "\n",
    "$$x = f(R^\\dagger y)$$\n",
    "\n",
    "where $R^\\dagger$ denotes the pseudo-inverse or **naive inversion** as explored in Tutorial_01. As we already saw, this inversion can lead to unfavorable results, and therefore we hope that the mapping $f$ removes artifacts and recovers a better solution. Therefore, in this setting the input output pairs consist of \n",
    "\n",
    "* $\\text{inp}_i$: the input in our cases is the noisy sinogram data of the $i$th ground truth image,\n",
    "* $\\text{oup}_i$: the output in our case is the $i$th ground truth image.\n",
    "\n",
    "\n",
    "### Some technical details\n",
    "\n",
    "For the learning setup we now switch the array/tensor backend from ```numpy``` to ```torch```. Furthermore, images will now have additional dimensions. Namely, the images $x$ will be of dimension\n",
    "\n",
    "$$\n",
    "B \\times C \\times N\\times N\n",
    "$$\n",
    "\n",
    "where\n",
    "\n",
    "* $B$ denotes the batch size, i.e., how many images we process simultaneously in one tensor,\n",
    "* $C$ denotes the number of channels, we always use $C=1$, but for RGB it would be $C=3$,\n",
    "* $N$ the image dimension, in our case given by the global variable ```IMG_SIZE```.\n",
    "\n",
    "The following commands are relevant, when we switch between ```numpy``` and ```torch```:\n",
    "\n",
    "* ```torch.tensor(x)```: can be used to convert a ```numpy``` array, to a ```torch``` tensor.\n",
    "* ```x.numpy()```: this converts a ```torch``` tensor, without a gradient, to a ```numpy``` array. Commands like ```plt.imshow``` do this internally.\n",
    "* ```x.detach()```: if the tensor ```x``` has a gradient, then we need to detach it first.\n",
    "* ```x[b,c,...]```: ```plt.imshow``` only works for 2D arrays, so we have to select one batch element $b$ and a channel $c$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3145e90-ebea-40b2-b389-ef2eff8e1588",
   "metadata": {},
   "source": [
    "## The forward operator\n",
    "\n",
    "As already mentioned, our forward operator is the limited angle Radon transform. Here, we utilize the same functionality as before, and integrate it in the torch framework.\n",
    "\n",
    "Here's a short discussion of this approach:\n",
    "\n",
    "* Disadvantages:\n",
    "    * Not a clean native ```torch``` solution, conversions between ```numpy``` and ```torch``` yield additional overhead. However, since we do not intend to work on the GPU this is acceptable.\n",
    "    * The underlying Radon functions are called from ```skimage```, which do not support batched input. In our case, we simply wrap a for-loop around the batch dimension. Performance-wise this is really bad, since such loops in Python are slow :(\n",
    "\n",
    "* Advantages:\n",
    "    * We can simply reutilize the code from before without changing much :) It's a quick solution, yielding a bit slower code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f461893-2c32-432a-8635-924341156d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from operators import Radon\n",
    "\n",
    "NUM_THETAS = 10\n",
    "ANGLES = (0, 90)\n",
    "theta = np.linspace(ANGLES[0], ANGLES[1], endpoint = False, num=NUM_THETAS)\n",
    "\n",
    "class Radon_torch:\n",
    "    def __init__(self, **kwargs):\n",
    "        self.R = Radon(**kwargs)\n",
    "    \n",
    "    def __call__(self, x, pbar=False):\n",
    "        x = x.numpy()\n",
    "        k = torch.zeros((x.shape[0], x.shape[2], self.R.num_theta))\n",
    "        for i in (trange(x.shape[0]) if pbar else range(x.shape[0])):\n",
    "            k[i] = torch.tensor(self.R(x[i,0,...]))\n",
    "\n",
    "        return k\n",
    "\n",
    "    def inverse(self, k, pbar=False):\n",
    "        k = k.numpy()\n",
    "        x = torch.zeros((k.shape[0], 1, k.shape[1], k.shape[1]))\n",
    "        for i in (trange(k.shape[0]) if pbar else range(x.shape[0])):\n",
    "            x[i] = torch.tensor(self.R.inverse(k[i]))\n",
    "        return x\n",
    "\n",
    "R = Radon_torch(theta=theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d2b9f3a-43fc-41b4-bfad-20c13f69c1c9",
   "metadata": {},
   "source": [
    "## Create Dataset\n",
    "\n",
    "Now we create our own dataset. As mentioned before it consists of input-output pairs:\n",
    "\n",
    "$$(Rx + \\epsilon, x)$$\n",
    "\n",
    "for randomly sampled images $x$. For utility functions, we save this data as a ```torch.utils.data.TensorDataset``` and create a loader with ```torch.utils.data.DataLoader```. This loader will later provide the functionality to easily iterate over the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff808405-7658-4c5e-9e24-3f8051b1b997",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import trange, tqdm\n",
    "\n",
    "train_p = 2\n",
    "num_images = 1000\n",
    "noise_lvl = 0.02\n",
    "x = torch.tensor(rwn(p=train_p, B=num_images), dtype=torch.float)[:, None, ...]\n",
    "x_recon = np.zeros((num_images, IMG_SIZE, IMG_SIZE))\n",
    "data = R(x, pbar=True) + noise_lvl * torch.normal(0, 1, size=(num_images, IMG_SIZE, NUM_THETAS))\n",
    "\n",
    "train_dataset = torch.utils.data.TensorDataset(data, x)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=5, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ae8b3c8-f226-45ca-93f3-ecde17f13dbf",
   "metadata": {},
   "source": [
    "## Let's look at our Data!\n",
    "\n",
    "In order to get data from the loader, we first transform it to an iterator with ```iter(train_loader)```. We obtain the first batch with ```next(iter(train_loader))```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe9b3ea9-8cb4-490c-a3f2-d5241acae1c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,3, figsize = (15,8))\n",
    "data, x = next(iter(train_loader)) #get_data(5, float('inf'), 0.01)\n",
    "\n",
    "for i, (z, title, kwargs) in enumerate([(data[0,...], 'Noisy data', {'cmap':'bone'}),\n",
    "                                        (R.inverse(data)[0,0,...], 'Naive inversion', IMG_KWARGS),\n",
    "                                        (x.detach()[0,0,...],'Target', IMG_KWARGS),\n",
    "                                        ]):\n",
    "                                        \n",
    "    ax[i].imshow(z, **kwargs)\n",
    "    ax[i].set_title(title)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea6ee58-3aad-47ae-b09e-3d5c33e79803",
   "metadata": {},
   "source": [
    "# Loading the model\n",
    "\n",
    "We now define the neural network model, we want to train in the following. Here, we use the celebrated UNet structure from this paper:\n",
    "\n",
    "<center>\n",
    "*Ronneberger, O., Fischer, P., & Brox, T. (2015). U-net: Convolutional networks for biomedical image segmentation. In Medical Image Computing and Computer-Assisted Interventionâ€“MICCAI 2015: 18th International Conference, Munich, Germany, October 5-9, 2015, Proceedings, Part III 18 (pp. 234-241). Springer International Publishing.*\n",
    "</center>\n",
    "\n",
    "\n",
    "The model architecture is reimplemented (and slightly compressed) in the ```models``` module. We will now load the model and check how many parameters we will train in the following. \n",
    "\n",
    "**Spoiler**: Quite a lot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9132076d-5bae-4d77-8e8b-d292d9d12de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import UNet\n",
    "model = UNet()\n",
    "\n",
    "model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "num_params = sum([np.prod(p.size()) for p in model_parameters])\n",
    "\n",
    "print('Loaded the model with ' + str(num_params) + ' trainable parameters')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6def8738-7649-4506-871e-7a2c98d3c0b1",
   "metadata": {},
   "source": [
    "## The reconstruction operator\n",
    "\n",
    "Our reconstruction operator can now be defined as $f_\\theta \\circ R^\\dagger$, where $f_\\theta$ denotes the post-processing network with parameters $\\theta$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e88066-8a58-43bf-9988-68aadb3f7c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recon(k, R):\n",
    "    Rinv = R.inverse(k)\n",
    "    return model(Rinv), Rinv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b66b535-8826-420c-b906-90f5b32bf50f",
   "metadata": {},
   "source": [
    "## How is the performance before training?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3435a0bf-833a-4744-bd1a-ab2e9de1a282",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,3, figsize = (15,8))\n",
    "data, x = next(iter(train_loader))\n",
    "x_recon, Rinv = recon(data, R)\n",
    "\n",
    "for i, (z, title) in enumerate([(x.detach()[0,0,...],'Target'), \n",
    "                                (Rinv[0,0,...], 'Naive inversion (network input)'), \n",
    "                                (x_recon.detach()[0,0,...], 'Model recon, before training')]):\n",
    "    ax[i].imshow(z, **IMG_KWARGS)\n",
    "    ax[i].set_title(title)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54708a49-2597-4b60-ac8d-f3ec4440e8af",
   "metadata": {},
   "source": [
    "# Training the model\n",
    "In order to train the model we consider the following minimization problem:\n",
    "\n",
    "$$\n",
    "\\min_\\theta \\mathbb{E}_{(x,y)\\sim \\mathcal{T}}\\left[ \\ell(f_\\theta(x), y)\\right]$$\n",
    "\n",
    "where\n",
    "\n",
    "* $\\theta$ denote the parameter of the neural network $f_\\theta$,\n",
    "* $x$ is the noisy, badly reconstructed input,\n",
    "* $y$ is the clean ground truth image,\n",
    "* $\\ell$ is the $L^2$ distance, i.e., $\\ell(\\hat y, y) = \\|\\hat y - y\\|^2$.\n",
    "\n",
    "In order to solve can use stochastic gradient descent, which yields the update\n",
    "\n",
    "$$\\theta \\gets \\theta - \\alpha \\ \\nabla_\\theta \\left(\\sum_{i=1}^B \\ell(f_\\theta(x_i), y_i)\\right).$$\n",
    "\n",
    "Here, $B$ denotes the batch size and $(x_1,y_1),\\ldots, (x_B,y_B)$ are the outputs of ```get_data``` in each step. The parameter $\\alpha$ denotes the step size.\n",
    "\n",
    "Alternatively, we employ the ADAM optimizer, which we define in the following cell. Additionally, we define a learning rate scheduler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a04363d8-9a8e-41c3-a5a0-5ce8c096d497",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "loss_fct = nn.MSELoss()\n",
    "opt = torch.optim.Adam(model.parameters(), lr=0.0005)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(opt, patience=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ee1e86a-fecb-439a-b44f-2e2217894f7c",
   "metadata": {},
   "source": [
    "### &#128221; <span style=\"color:darkorange\"> Task 3.1 </span>\n",
    "#### Training the network\n",
    "\n",
    "We now define the train loop, that updates the variables $\\theta$. Here, we use the ```autograd``` functionality of ```torch```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af86987-3c62-4268-8031-7d28248afa41",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "epochs = 3\n",
    "for e in trange(epochs, desc=\"Epochs\"):\n",
    "    bbar = tqdm(total=len(train_loader), desc=\"Batches in epoch: \" + str(e))\n",
    "    for data, x in iter(train_loader):\n",
    "        opt.zero_grad() # zero out gradients from previous step\n",
    "        x_recon, Rinv = recon(data, R) # compute the pseudo inverse and the post processed reconstruction\n",
    "        loss = loss_fct(x_recon, x) # compute the loss\n",
    "        loss.backward() # compute the gradients\n",
    "        opt.step() # make a step of the optimizer\n",
    "        scheduler.step(loss) # make a scheduler step\n",
    "    \n",
    "        # additonal computations and plotting\n",
    "        loss1 = loss.item()\n",
    "        loss2 = loss_fct(Rinv, x).item()\n",
    "    \n",
    "        print(30*'-')\n",
    "        print('Epoch: ' + str(e))\n",
    "        print('Current loss:' + str(loss1))\n",
    "        print('Naive inversion loss:' + str(loss2))\n",
    "        for param_group in opt.param_groups:\n",
    "            print('Current lr:' + str(param_group['lr']))\n",
    "        bbar.update(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b83193fc-53ad-474a-9fa2-9e83492d2acc",
   "metadata": {},
   "source": [
    "## How does the reconstruction look now?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa0cfa6-a21a-48eb-8dc2-4629b67001b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,3, figsize = (15,8))\n",
    "data, x = next(iter(train_loader)) #get_data(5, float('inf'), 0.01)\n",
    "x_recon, Rinv = recon(data, R)\n",
    "\n",
    "for i, (z, title) in enumerate([(x.detach()[0,0,...],'Target'), \n",
    "                                (Rinv[0,0,...], 'Naive inversion (network input)'), \n",
    "                                (x_recon.detach()[0,0,...], 'Model recon, after training')]):\n",
    "    ax[i].imshow(z, **IMG_KWARGS)\n",
    "    ax[i].set_title(title)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7a8e018-7867-447a-8b0d-acdb8103e28a",
   "metadata": {},
   "source": [
    "## Saving and loading the models\n",
    "If you want, you can save or load models with the functions below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e4d80e-d982-40b4-b6f4-e583f2641519",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "name = 'UNet-train-p-' + str(train_p) + str(datetime.datetime.now().strftime('%Y%m%dT%H%M%SZ')) + '.pt'\n",
    "save_model = True\n",
    "if save_model:\n",
    "    torch.save(model.state_dict(), name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a4348c3-6e58-48c6-ab85-1fdbd758143c",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_model = False\n",
    "name = 'UNet-train-p-220240916T171815Z.pt'\n",
    "if load_model:\n",
    "    model.load_state_dict(torch.load(name))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3094bb8-7d9c-4fd0-8ede-a9a77b67f5fa",
   "metadata": {},
   "source": [
    "### &#128221; <span style=\"color:darkorange\"> Task 3.2 </span>\n",
    "#### Evaluating the results\n",
    "\n",
    "The cell below allows you to test the performance of your trained model.\n",
    "\n",
    "Your task is to try out different shapes, noise levels and angle specification and evaluate the performance of your model :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12eb9d18-af1f-43fb-8cd6-dc7d971ead08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Test\n",
    "from utils import get_phantom\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interactive\n",
    "from IPython.display import display\n",
    "\n",
    "img_size_test=64\n",
    "im_kwargs = {'vmin':0., 'vmax':1., 'cmap':'bone'}\n",
    "\n",
    "def plot_result(logp, noise_lvl, angle):\n",
    "    theta = np.linspace(angle[0],angle[1], endpoint = False, num=NUM_THETAS)\n",
    "    R = Radon_torch(theta=theta)\n",
    "    p = 2**logp if logp < 10 else float('inf')\n",
    "    x = torch.tensor(rwn(p=p))\n",
    "    \n",
    "    data = R(x[:,None,...]) + noise_lvl * torch.normal(0, 1, size=(IMG_SIZE, NUM_THETAS))\n",
    "    \n",
    "    x_recon, Rinv = recon(data, R)\n",
    "    x_recon = x_recon.detach().numpy()[0,0,...]\n",
    "    \n",
    "    fig, ax = plt.subplots(1,3, figsize = (20,15))\n",
    "\n",
    "    for i, (z, title) in enumerate([(x[0],'Ground truth'), (Rinv[0,0,...], 'Naive recon'), (x_recon,'Network recon')]):  \n",
    "        ax[i].imshow(z, **im_kwargs)\n",
    "        ax[i].set_title(title + ', error: '+str(round(np.linalg.norm(x - z), 4)))\n",
    "    ax[0].set_title('p=' +str(p))\n",
    "\n",
    "\n",
    "p_slider = widgets.FloatSlider(min = 0.0, max = 10., step = 1, value = np.log(train_p)/np.log(2), continuous_update = False)\n",
    "n_slider = widgets.FloatSlider(min = 0.0, max = .03, step = 0.001, value = 0.01, continuous_update = False)\n",
    "a_slider = widgets.FloatRangeSlider(value=[0, 90],min=0,max=180,step=10,continuous_update=False)\n",
    "\n",
    "interactive_plot = interactive(plot_result,logp = p_slider, angle=a_slider, noise_lvl=n_slider)\n",
    "display(interactive_plot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d32bd23-727e-4ef3-bf83-756bb539c5ea",
   "metadata": {},
   "source": [
    "# How can we combine model and data driven approaches?\n",
    "\n",
    "A popular way to combine model and data driven approaches are so-called plug-and-play (PnP) methods. The starting point is a variational minimization problem\n",
    "\n",
    "$$\\min_x \\frac{1}{2}\\, \\|Ax - y\\|^2 + \\lambda J(x).$$\n",
    "\n",
    "This problem can be solved via prox-based methods, for example an ADMM update scheme\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "x &\\gets \\operatorname*{arg min}_{x}\\ \\frac{1}{2}\\, \\|Ax - y\\|^2 + \\frac{\\rho}{2} \\|{v - u}\\|^2,\\\\\n",
    "v &\\gets \\operatorname*{arg min}_{v}\\ \\lambda J(v) + \\frac{\\rho}{2} \\|{v - (x + u)}\\|^2,\\\\\n",
    "u &\\gets u + x - v.\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "Here, the first line can be solved can be solved with a linear solver (e.g. the cg iteration) and the last line ist explicit. The second line is in fact the prox operator of $J$ since \n",
    "\n",
    "$$\\operatorname{prox}_{\\lambda/\\rho\\ J}(x+u) =  \\operatorname*{arg min}_{v}\\ \\lambda J(v) + \\frac{\\rho}{2} \\|{v - (x + u)}\\|^2.$$\n",
    "\n",
    "Evaluating this prox can be complicated and relies on a possibly hand-crafted functional $J$. The idea of PnP methods consists of replacing a prox step of this kind by an arbitrary map $D$. I.e. the iteration takes the form\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "x &\\gets \\operatorname*{arg min}_{x}\\ \\frac{1}{2}\\, \\|Ax - y\\|^2 + \\frac{\\rho}{2} \\|{v - u}\\|^2,\\\\\n",
    "v &\\gets D_\\lambda(x + u),\\\\\n",
    "u &\\gets u + x - v.\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "Typically, this function $D$ is a simple denoiser, i.e., a mapping that takes a noisy image and outputs a clear version.\n",
    "\n",
    "## Training the denoiser\n",
    "\n",
    "We want to try out the PnP approaches from above. To do so, we first train a denoiser $D$. Here, we use the same setup as before, we just have to change the dataset. Namely, we want the denoiser to minimize the following term,\n",
    "\n",
    "$$ \\mathbb{E}_{x,\\varepsilon} \\|D(x + \\varepsilon) - x\\|_2.$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69702069-bddd-4a46-8284-7e7f78a8b4d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_lvl = 0.2\n",
    "x    = torch.tensor(rwn(p=2, B=num_images), dtype=torch.float)[:, None, ...]\n",
    "data = x + noise_lvl *  torch.normal(0., 1., size=x.shape)\n",
    "\n",
    "train_dataset_denoising = torch.utils.data.TensorDataset(data, x)\n",
    "train_loader_denoising = torch.utils.data.DataLoader(train_dataset_denoising, batch_size=5, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fc4db94-b05c-4519-90f3-d09c30fa7a32",
   "metadata": {},
   "source": [
    "## Look at the data again\n",
    "\n",
    "The data looks slightly different now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ecab9a-14fa-4d47-b2d8-e6fd2c0a8c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "data, x = next(iter(train_loader_denoising))\n",
    "\n",
    "fig, ax = plt.subplots(1,2, figsize = (10,8))\n",
    "for i, (z,title) in enumerate([(data, 'Noisy data'), (x, 'Original')]):\n",
    "    ax[i].imshow(z[0,0,...], **IMG_KWARGS)\n",
    "    ax[i].set_title(title)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faff4daf-f591-4083-9f3d-b36d4504d35f",
   "metadata": {},
   "source": [
    "### &#128221; <span style=\"color:darkorange\"> Task 3.3 </span>\n",
    "#### Train again\n",
    "\n",
    "With the same set up as before you can now train the denoising model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b18ed0-b352-442f-942a-651123880da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "denoiser = UNet()\n",
    "opt = torch.optim.Adam(denoiser.parameters(), lr=0.001)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(opt, patience=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1edd6a93-8910-4313-8415-e16ede97aab7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "epochs = 3\n",
    "\n",
    "for e in trange(epochs):\n",
    "    bbar = tqdm(total=len(train_loader_denoising), desc=\"Batches in epoch\")\n",
    "    for data, x in iter(train_loader_denoising):\n",
    "        opt.zero_grad() # zero out gradients from previous step\n",
    "        x_recon = denoiser(data)\n",
    "        loss = loss_fct(x_recon, x) # compute the loss\n",
    "        loss.backward() # compute the gradients\n",
    "        opt.step() # make a step of the optimizer\n",
    "        scheduler.step(loss) # make a scheduler step\n",
    "    \n",
    "        print(30*'-')\n",
    "        print('Epoch: ' + str(e))\n",
    "        print('Current Loss:' + str(loss.item()))\n",
    "        for param_group in opt.param_groups:\n",
    "            print('Current lr:' + str(param_group['lr']))\n",
    "        bbar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b61a3b6-7fe0-458c-8437-5b8517cd1820",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model = True\n",
    "name = 'UNet-denoiser-train-p-' + str(train_p) + str(datetime.datetime.now().strftime('%Y%m%dT%H%M%SZ')) + '.pt'\n",
    "if save_model:\n",
    "    torch.save(denoiser.state_dict(), name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41fbcd36-80a6-4bf0-924d-9b1d3c618b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_model = False\n",
    "name = 'UNet-denoiser-train-p-220240916T175542Z.pt'\n",
    "if load_model:\n",
    "    denoiser.load_state_dict(torch.load(name))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66cd5816-cd60-40b9-a2cd-a9a8aaf135c7",
   "metadata": {},
   "source": [
    "# How well does it work?\n",
    "The cell below shows the denoising performance of the trained network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ebfa2f-e0d9-4367-800a-16ae5d2331ce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data, x = next(iter(train_loader_denoising))\n",
    "x_recon = denoiser(data).detach()\n",
    "\n",
    "fig, ax = plt.subplots(1,3, figsize = (10,8))\n",
    "for i, (z,title) in enumerate([(x, 'Original'), (data, 'Noisy data'), (x_recon, 'Model recon')]):\n",
    "    ax[i].imshow(z[0,0,...], **IMG_KWARGS)\n",
    "    ax[i].set_title(title)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a3c3c62-6834-455d-a0e9-55a78fb4cf49",
   "metadata": {},
   "source": [
    "## Defining the PnP prox substitute\n",
    "\n",
    "Our original goal was to substitute the prox in the admm itertion. In the module ```optimizer``` the optimizer ```admm``` is defined. It has the following signature for initialization:\n",
    "\n",
    "```admm(R, x0, Rx, rho=0.4, lamda=1., verbosity=0, prox=model_prox, max_it=35, max_inner_it=1)```\n",
    "\n",
    "where\n",
    "\n",
    "* ```R``` is the linear operator, i.e. the Radon trafo\n",
    "* ```x0``` is the inital guess\n",
    "* ```rho``` is an iteration parameter\n",
    "* ```lamda``` scales the influence of the prox\n",
    "* ```prox``` defines the prox mapping\n",
    "* ```max_it``` determines the umber of steps\n",
    "* ```max_inner_it``` determines the number of inner iterations\n",
    "\n",
    "We just have to define the prox maping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca142b72-81f0-4d7b-977a-0a3e7ec48745",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_quasi_prox(x, lamda):\n",
    "    lamda = max(min(lamda, 1.),0)\n",
    "    return (1-lamda) * x + lamda * denoiser(x).detach().numpy()[0,0,...]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00c714e3-0502-407b-ad1e-5f355a177eeb",
   "metadata": {},
   "source": [
    "### &#128221; <span style=\"color:darkorange\"> Task 3.4 </span>\n",
    "#### Test the performance on the CT problem\n",
    "\n",
    "With the following cell you can now test how well the denoiser and the PnP-ADMM iteration performs on the CT reconstruction task. How does the noise level influence the performance?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d9efcb-ab4e-459b-bfa9-877a0fe954fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from optimizers import admm\n",
    "\n",
    "min_angle = 0\n",
    "max_angle = 90\n",
    "theta = np.linspace(min_angle, max_angle, endpoint = False, num=NUM_THETAS)\n",
    "R_np = Radon(theta=theta)\n",
    "p = 2\n",
    "\n",
    "def plot_recon(noise_lvl, logp, lamda):\n",
    "    p = 2**logp if logp < 10 else float('inf')\n",
    "    x = rwn(p=p)[0]\n",
    "    \n",
    "    data = R_np(x)\n",
    "    data += noise_lvl * np.random.normal(0,1, size=data.shape)\n",
    "    x0 = R_np.inverse(data)\n",
    "    \n",
    "    \n",
    "    pnpadmm = admm(R_np, x0, data, rho=0.4, lamda=lamda, verbosity=0, prox=model_quasi_prox, max_it=35, max_inner_it=5)\n",
    "    pnpadmm.solve()\n",
    "    \n",
    "    x_model = denoiser(x0).detach().numpy()[0,0,...]\n",
    "    fig, ax = plt.subplots(1,4, figsize=(20,15))\n",
    "\n",
    "    for i, (z, title) in enumerate([(x, 'Original'),\n",
    "                                    (x0, 'Naive recon'),\n",
    "                                    (x_model, 'Denoiser output, error: ' + str(np.linalg.norm(x_model - x))),\n",
    "                                    (pnpadmm.x, 'PnP ADMM Recon, error: ' + str(np.linalg.norm(pnpadmm.x - x))),\n",
    "                                   ]):\n",
    "                                    \n",
    "    \n",
    "        ax[i].imshow(z,**IMG_KWARGS)\n",
    "        ax[i].set_title(title)\n",
    "\n",
    "\n",
    "\n",
    "n_slider = widgets.FloatSlider(min = 0.0, max = .1, step = 0.001, value = 0.02, continuous_update = False)\n",
    "p_slider = widgets.FloatSlider(min = 0.0, max = 10., step = 1, value = np.log(train_p)/np.log(2), continuous_update = False)\n",
    "l_slider = widgets.FloatSlider(min = 0.0, max = 5., step = 0.1, value = 5., continuous_update = False)\n",
    "interactive_plot = interactive(plot_recon, noise_lvl = n_slider, logp = p_slider, lamda = l_slider)\n",
    "display(interactive_plot)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
